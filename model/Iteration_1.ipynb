{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Airbnb Price Prediction - Optimizing Listings\n",
    "#### Patrick Huston & Filippos Lymperopoulos | Spring 2016\n",
    "\n",
    "*This notebook aims to document our process in creating a ML pipeline to predict Airbnb listing prices given an input set of features. A major focus of this exploration is to write modular, well-designed components that could easily be taken and applied to a different modeling situation.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import pickle\n",
    "from sklearn import preprocessing\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "import binaryHelper as be\n",
    "import sumHelper as se\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.cross_validation import StratifiedKFold\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "from sklearn import linear_model\n",
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Data\n",
    "\n",
    "Airbnb provides an expansive listings dataset for public use. It includes all listings for major cities around the world. For the purpose of our exploration, we'll start off by using well-known US cities - Boston, San Francisco, Los Angeles, Washington DC, and Seattle. For each listing, Airbnb provides a large amount of features - check [here](https://github.com/flymperopoulos/DataScience16CTW/blob/master/report/listings_features.md) to see them all listed out."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load in the Listings Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda/lib/python2.7/site-packages/IPython/core/interactiveshell.py:2902: DtypeWarning: Columns (40) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "listingsBoston = pd.read_csv('../data/listingsBoston.csv')\n",
    "listingsSF = pd.read_csv('../data/listingsSF.csv')\n",
    "listingsLA = pd.read_csv('../data/listingsLA.csv')\n",
    "listingsDC = pd.read_csv('../data/listingsDC.csv')\n",
    "listingsSeattle = pd.read_csv('../data/listingsSeattle.csv')\n",
    "\n",
    "frames = [listingsBoston, listingsSF, listingsLA, listingsDC, listingsSeattle]\n",
    "\n",
    "listingsAll = pd.concat(frames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load in the Calendar Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "calendarBoston = pd.read_csv('../data/calendarBoston.csv')\n",
    "calendarSF = pd.read_csv('../data/calendarSF.csv')\n",
    "calendarLA = pd.read_csv('../data/calendarLA.csv')\n",
    "calendarDC = pd.read_csv('../data/calendarDC.csv')\n",
    "calendarSeattle = pd.read_csv('../data/calendarSeattle.csv')\n",
    "\n",
    "frames = [calendarBoston, calendarSF, calendarLA, calendarDC, calendarSeattle]\n",
    "\n",
    "calendarAll = pd.concat(frames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning Convenience\n",
    "\n",
    "To facilitate the process of cleaning, we've defined a cleaning helper and cleaning processor class below. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering \n",
    "\n",
    "The Airbnb dataset is composed of both numerical features - data like the number of beds, the number of bedrooms, and the number of bathrooms - and categorical features - data like the neighborhood, the type of room, and the type of the bed. \n",
    "\n",
    "Both types of features will be important in predicting the price of a given listing. While the numerical features can be used directly, we'll have to take some additional processing and encoding steps to get the categorical data in a representation that can be used as a feature in our models.\n",
    "\n",
    "#### Numerical Features\n",
    "\n",
    "The numerical features we plan on using directly are the following:\n",
    "- `bedrooms` - The number of bedrooms included in the listing\n",
    "- `beds` - The number of beds included in the listing\n",
    "- `bathrooms` - The number of bathrooms included in the listing\n",
    "- `accommodates` - The number of people the listing accommodates\n",
    "\n",
    "Other non-categorical features we'll be extracting are:\n",
    "- `num_amenities` - Using the 'amenities' feature, we can extract the number of amenities offered\n",
    "- `days_host` - Using the 'host_since' feature, we can compute the number of days the host has been a host, potentially a measure of experience\n",
    "- `price` - We must clean the 'price' feature to extract a numerical (rather than string) value for the price of the listing\n",
    "\n",
    "#### Categorical Features\n",
    "\n",
    "There are several pertinent categorical features that intuitively seem to have great significance in the price of the listing. To use them in a model, however, we'll need to take some steps to encode them numerically. Listed here are the features we'll be using in the model:\n",
    "\n",
    "- `neighbourhood` - The neighbourhood the property is in\n",
    "- `property_type` - The type of property (e.g. apartment, bed and breakfast, house)\n",
    "- `room_type` - The type of room (e.g. Shared room, Entire home/apt, or Private room\n",
    "- `bed_type` - The type of bed offered (e.g. Real Bed, Futon, Couch, Pull-out Sofa, Airbed\n",
    "\n",
    "\n",
    "There are several options for encoding categorical features.\n",
    "\n",
    "##### Ordinal Encoding\n",
    "\n",
    "In ordinal encoding, in which each categorical value takes on an integer value. The ations of ordinal encoding are that it doesn't add extra columsn in the feature matrix, which can dilute the other features included. The major drawback of an ordinal encoding is that it inserts a notion of a relationship between each category and the dependent variable (price, in this case). In some situations, this may be appropriate (e.g. in the bed_type feature, there is a natural ordering/relationship between the bed_type and the price of the listing.\n",
    "\n",
    "##### One-Hot (Dummy) Encoding\n",
    "\n",
    "In a one-hot encoding scheme, each category is represented as its own new feature that takes on a binary value - 1 if the input fits into a given category. For a category with *n* levels, this means adding *n* new columns to our feature matrix. For low values of *n*, this may be okay, but higher values of *n* risk the possibiilty of blowing the dimensionality of the feature matrix way out of proportion. \n",
    "\n",
    "##### Binary Encoding\n",
    "\n",
    "Binary encoding is a cool alternative to one-hot encoding for the representation of categorical values. First, each value takes on an integer value in an ordinal encoding. From this, each value may be represented as a binary number. Finally, this binary number is split up into individual bits, and each is inserted into the feature matrix as a new column. \n",
    "\n",
    "### Encoding Choices\n",
    "\n",
    "Armed with a wealth of information on categorical encoding, we made the following decisions for each of the categorical features in the dataset.\n",
    "\n",
    "#### Neighbourhood\n",
    "Due to its high dimensionality (420 possibilities), we chose a binary encoding to represent the neighbourhood feature. An ordinal encoding might also be possible, but in research we've done, a binary encoding almost always seemed to ourperform ordinal encodings.\n",
    "\n",
    "#### Property Type\n",
    "Property was another category that had multiple dimensions (26 options), hence we decided to process the categorical data by encoding them with a binary method. We initially attempted sum encoding however that did not yield improved results. We ended up reducing the \"represented\" number of features from 26 to 5. \n",
    "\n",
    "#### Room Type & Bed Type\n",
    "Observing the results from the previous encoding procedures we decided to perform a different form of encoding, where we utilized a combination of one-hot and binary encoding. This method significantly aided our model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def create_ordinal_mapping(data, parameter):\n",
    "    parameter_mapping = {}\n",
    "    \n",
    "    for index, parameter in enumerate(sorted(data[parameter].unique())):\n",
    "        parameter_mapping[parameter] = index\n",
    "    \n",
    "    return parameter_mapping\n",
    "\n",
    "neighbourhood_mapping = create_ordinal_mapping(listingsAll, \"neighbourhood_cleansed\")\n",
    "bed_type_mapping = create_ordinal_mapping(listingsAll, \"bed_type\")\n",
    "room_type_mapping = create_ordinal_mapping(listingsAll, \"room_type\")\n",
    "property_type_mapping = create_ordinal_mapping(listingsAll, \"property_type\")\n",
    "\n",
    "# Sorting based on room quality\n",
    "shared_room_ord = room_type_mapping[\"Shared room\"] \n",
    "entire_apt_ord = room_type_mapping[\"Entire home/apt\"]\n",
    "room_type_mapping[\"Shared room\"] = entire_apt_ord\n",
    "room_type_mapping[\"Entire home/apt\"] = shared_room_ord"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Helper\n",
    "\n",
    "The class `Helper` exposes a set of helpful functions that each deal with processing an individual feature in the dataset. For example, `amenities_to_list` takes in an individual row from the `amenities` column - represented as a string - and converts it into a more useful list format. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Helper():\n",
    "    def __init__(self, data_attrs):\n",
    "        self.data_attrs = data_attrs\n",
    "    \n",
    "    # Converts string representation of amenities list \n",
    "    def amenities_to_list(self, amenities):\n",
    "        amenities = amenities.replace('{', '')\n",
    "        amenities = amenities.replace('}', '')\n",
    "        amenities = amenities.replace('\\\"', '')\n",
    "        return amenities.split(',')\n",
    "\n",
    "    # Creates new feature out of the number of amenities\n",
    "    def num_amenities(self, amenitiesList):\n",
    "        return len(amenitiesList)\n",
    "\n",
    "    # Converts string representation of price to float \n",
    "    def price_to_int(self, price):\n",
    "        price = price.replace(',', '')\n",
    "        price = price.replace('$', '')\n",
    "        return float(price)\n",
    "    \n",
    "    def date_to_days(self, startDay):\n",
    "        dStart = datetime.strptime(startDay, \"%Y-%m-%d\")\n",
    "        dEnd = datetime.strptime(self.data_attrs['date_min'], \"%Y-%m-%d\")\n",
    "        return abs((dEnd - dStart).days)\n",
    "    \n",
    "    def row_to_ordinal(self, row, mapping):\n",
    "        return self.data_attrs[mapping][row]\n",
    "\n",
    "    \n",
    "helper = Helper({'date_min': listingsAll[listingsAll.host_since.isnull() == False].host_since.max(), \n",
    "                 'neighbourhood_mapping': neighbourhood_mapping, \n",
    "                 'bed_type_mapping':bed_type_mapping, \n",
    "                 'room_type_mapping':room_type_mapping,\n",
    "                 'property_type_mapping':property_type_mapping\n",
    "                });"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clean Processor\n",
    "The class `cleanProcessor` does handles two things - it applies the methods defined in `Helper` to its dataset and performs some additional processing like null-filling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class cleanProcessor():\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "        \n",
    "    def clean_listings(self):\n",
    "        df_clean = self.data.copy()\n",
    "        \n",
    "        # TODO: What? - Better techniques for filling nulls\n",
    "        df_clean.loc[df_clean.review_scores_rating.isnull(), 'review_scores_rating'] = 90\n",
    "        df_clean.loc[df_clean.host_since.isnull(), 'host_since'] = '2015-10-02'\n",
    "        df_clean.loc[df_clean.bedrooms.isnull(), 'bedrooms'] = 0\n",
    "        df_clean.loc[df_clean.bathrooms.isnull(), 'bathrooms'] = 0\n",
    "        df_clean.loc[df_clean.beds.isnull(), 'beds'] = 0\n",
    "        df_clean.loc[df_clean.property_type.isnull(), 'property_type'] = \"Other\"\n",
    "        \n",
    "        df_clean['amenities'] = df_clean['amenities'].apply(helper.amenities_to_list)\n",
    "        df_clean['num_amenities'] = df_clean['amenities'].apply(helper.num_amenities)\n",
    "        df_clean['price'] = df_clean['price'].apply(helper.price_to_int)\n",
    "        df_clean['days_host'] = df_clean['host_since'].apply(helper.date_to_days)\n",
    "        df_clean['neighbourhood_binary'] = df_clean['neighbourhood_cleansed'].apply(helper.row_to_ordinal, args=(\"neighbourhood_mapping\",))\n",
    "        df_clean['property_binary_encoded'] = df_clean['property_type'].apply(helper.row_to_ordinal, args=(\"property_type_mapping\",))\n",
    "        \n",
    "        # Binary encoding for neighborhoods\n",
    "        encoder = be.BinaryEncoder(cols=['neighbourhood_binary'])\n",
    "        binary_neighbourhoods = encoder.transform(df_clean)\n",
    "        \n",
    "        # Sum encoding for property type\n",
    "        property_encoder = be.BinaryEncoder(cols=['property_binary_encoded'])\n",
    "        binary_properties = property_encoder.transform(df_clean)\n",
    "        \n",
    "        # One-hot and Ordinal Encoding for bed_type and room_type\n",
    "        bed_type = pd.get_dummies(df_clean.bed_type)    \n",
    "        df_clean[\"bed_type\"] = df_clean[\"bed_type\"].apply(helper.row_to_ordinal, args=(\"bed_type_mapping\",))\n",
    "        print df_clean[\"bed_type\"]\n",
    "        room_type = pd.get_dummies(df_clean.room_type)    \n",
    "        df_clean[\"room_type\"] = df_clean[\"room_type\"].apply(helper.row_to_ordinal, args=(\"room_type_mapping\",))\n",
    "\n",
    "        # One-hot encoding for cancellation policy\n",
    "        cancellation_policy = pd.get_dummies(df_clean.cancellation_policy)\n",
    "        cancellation_policy.rename(columns={'strict':'cancellation_strict'})\n",
    "        cancellation_policy.rename(columns={'flexible':'cancellation_flexible'})\n",
    "        cancellation_policy.rename(columns={'moderate':'cancellation_moderate'})\n",
    "                \n",
    "        data = pd.concat([df_clean, cancellation_policy, binary_neighbourhoods, bed_type, room_type, binary_properties], axis=1)\n",
    "\n",
    "        return data\n",
    "\n",
    "    def clean_calendar(self):\n",
    "        self.df_clean = df.copy()\n",
    "        self.df_clean = self.df_clean[self.df_clean.available == 't']\n",
    "        self.df_clean['price'] = self.df_clean['price'].apply(helper.price_to_int)\n",
    "        return self.df_clean\n",
    "\n",
    "clean_processor_listings = cleanProcessor(listingsAll)\n",
    "clean_processor_calendar = cleanProcessor(calendarAll)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now, let's use our clean_processor to clean our listings data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       4\n",
      "1       4\n",
      "2       4\n",
      "3       4\n",
      "4       4\n",
      "5       4\n",
      "6       4\n",
      "7       4\n",
      "8       4\n",
      "9       4\n",
      "10      4\n",
      "11      4\n",
      "12      4\n",
      "13      4\n",
      "14      4\n",
      "15      4\n",
      "16      4\n",
      "17      4\n",
      "18      4\n",
      "19      4\n",
      "20      4\n",
      "21      4\n",
      "22      4\n",
      "23      4\n",
      "24      4\n",
      "25      4\n",
      "26      4\n",
      "27      4\n",
      "28      4\n",
      "29      4\n",
      "       ..\n",
      "3788    4\n",
      "3789    4\n",
      "3790    4\n",
      "3791    4\n",
      "3792    4\n",
      "3793    4\n",
      "3794    4\n",
      "3795    4\n",
      "3796    4\n",
      "3797    2\n",
      "3798    4\n",
      "3799    4\n",
      "3800    4\n",
      "3801    4\n",
      "3802    4\n",
      "3803    4\n",
      "3804    4\n",
      "3805    4\n",
      "3806    4\n",
      "3807    4\n",
      "3808    4\n",
      "3809    4\n",
      "3810    4\n",
      "3811    4\n",
      "3812    4\n",
      "3813    4\n",
      "3814    4\n",
      "3815    4\n",
      "3816    4\n",
      "3817    4\n",
      "Name: bed_type, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "listingsClean = clean_processor_listings.clean_listings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Private -- 80.0 \n",
      "Shared -- 47.0 \n",
      "Entire -- 159.0 \n"
     ]
    }
   ],
   "source": [
    "print '{} -- {} '.format('Private', listingsClean[listingsClean.room_type == 1].price.median()) \n",
    "print '{} -- {} '.format('Shared', listingsClean[listingsClean.room_type == 0].price.median()) \n",
    "print '{} -- {} '.format('Entire', listingsClean[listingsClean.room_type == 2].price.median()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Real Bed': 4, 'Futon': 2, 'Couch': 1, 'Pull-out Sofa': 3, 'Airbed': 0}\n"
     ]
    }
   ],
   "source": [
    "print bed_type_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Real -- 120.0 \n",
      "Pull-out -- 79.5 \n",
      "Futon -- 70.0 \n",
      "Air -- 65.0 \n",
      "Couch -- 55.0 \n"
     ]
    }
   ],
   "source": [
    "print '{} -- {} '.format('Real', listingsClean[listingsClean.bed_type == 4].price.median())\n",
    "print '{} -- {} '.format('Pull-out', listingsClean[listingsClean.bed_type == 3].price.median()) \n",
    "print '{} -- {} '.format('Futon', listingsClean[listingsClean.bed_type == 2].price.median()) \n",
    "print '{} -- {} '.format('Air', listingsClean[listingsClean.bed_type == 0].price.median()) \n",
    "print '{} -- {} '.format('Couch', listingsClean[listingsClean.bed_type == 1].price.median()) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choosing Models\n",
    "\n",
    "Now that we've done a good amount of initial preprocessing on our data, let's move towards some predictive modeling. Our goal is to develop a model that will predict a price given listing parameters. We'll experiment with including different features, and see which combination fo features and models produces the best results.\n",
    "\n",
    "After some initial research we've decided to start off by trying four different models - \n",
    "\n",
    "1. Linear Lasso\n",
    "       The Lasso is a linear model that estimates sparse coefficients. It is useful in some contexts due to its tendency to prefer solutions with fewer parameter values, effectively reducing the number of variables upon which the given solution is dependent.\n",
    "       \n",
    "2. ElasticNet \n",
    "       ElasticNet is a linear regression model trained with L1 and L2 prior as regularizer. This combination allows for learning a sparse model where few of the weights are non-zero like Lasso, while still maintaining the regularization properties of Ridge.\n",
    "       \n",
    "3. Support Vector Regression\n",
    "       Support Vector Regression is an implementation of regression that uses the SVM approach. In this case, we'll be using the linear kernel.\n",
    "            \n",
    "4. Ridge Regression\n",
    "       Ridge regression addresses some of the problems of Ordinary Least Squares by imposing a penalty on the size of coefficients. The ridge coefficients minimize a penalized residual sum of squares.\n",
    "       \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Linear Lasso\n",
    "lasso = linear_model.Lasso(alpha = .01)\n",
    "\n",
    "# ElasticNet\n",
    "elasticNet = linear_model.ElasticNet(alpha = 0.1, l1_ratio=0.7)\n",
    "\n",
    "# Ridge Regression\n",
    "ridgeRegression = linear_model.Ridge(alpha = .5)\n",
    "\n",
    "# Support Vector Regression\n",
    "svr = svm.SVR(C=1.0, epsilon=0.2)\n",
    "\n",
    "models = {'lasso': lasso, 'elasticNet': elasticNet, 'ridgeRegression': ridgeRegression }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing Models\n",
    "\n",
    "Now, let's define `ModelHelper`, a class that will facilitate the process of testing our models.\n",
    "\n",
    "#### A quick note on testing\n",
    "\n",
    "To test our model, we'll be using the `cross_val_score` method provided by scikit-learn. Additionally, we'll be using `cross_val_score` coupled with a StratifiedKFold train-test splitting step. This step ensures that each neighborhood will have equal representation in both the training and test datasets. This is necessary because the data is sorted by neighbourhood. By default, a train-test split would likely give us training and test sets where a given neighbourhood only appears in one or the other - essentially nullifying the predictive power of the neighbourhood as a feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class ModelHelper():\n",
    "    ''' \n",
    "    ModelHelper exposes a set of functions aimed at facilitating the dataset\n",
    "    manipulation (train-test splitting) and model testing process\n",
    "    '''\n",
    "    \n",
    "    def __init__(self, X, y, features):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.XFeat = X[features]\n",
    "    \n",
    "    def cross_validate(self, model, cv=3):\n",
    "        '''Cross-validates model within trainnig set with a split of 'cv' - default value of 3'''\n",
    "        cv = StratifiedKFold(self.X.neighbourhood_cleansed)\n",
    "        return cross_val_score(model, self.XFeat, self.y, cv=cv).mean()\n",
    "\n",
    "    def train_test_splitter(self, model, train_size=0.6, save=False):\n",
    "        '''Performs train-test split on data, trains on train, tests on test, returns score, model, data'''\n",
    "        X_train, X_test, y_train, y_test = train_test_split(self.XFeat, self.y, train_size=train_size)\n",
    "        model.fit(X_train, y_train)\n",
    "        return X_train, X_test, y_train, y_test, model\n",
    "\n",
    "    def test_models(self, models):\n",
    "        '''Iterates over all different models and print out their results of train_test_splitter'''\n",
    "        for modelName, model in models.iteritems():\n",
    "            print '{} : {}'.format(modelName, self.cross_validate(model))\n",
    "    \n",
    "    def save_model(self, fitted_model, filename=\"model.pkl\"):\n",
    "        '''Persists model to disk for later use in backend API'''\n",
    "        joblib.dump(fitted_model, filename) \n",
    "\n",
    "    def save_mappings(self, filename=\"mappings.pkl\"):\n",
    "        '''Persists model to disk for later use in backend API'''\n",
    "        property_type_mapping_copy = property_type_mapping.copy()\n",
    "        room_type_mapping_copy = room_type_mapping.copy()\n",
    "        bed_type_mapping.update(property_type_mapping_copy)\n",
    "        bed_type_mapping.update(room_type_mapping_copy)        \n",
    "        bed_type_mapping.update(neighbourhood_mapping)\n",
    "        return bed_type_mapping\n",
    "        #         joblib.dump(bed_type_mapping, filename) \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "binary_encoded_properties = [\"property_binary_encoded_{}\".format(i) for i in range(5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['num_amenities', 'bedrooms', 'beds', 'neighbourhood_binary_0', 'neighbourhood_binary_1', 'neighbourhood_binary_2', 'neighbourhood_binary_3', 'neighbourhood_binary_4', 'neighbourhood_binary_5', 'neighbourhood_binary_6', 'neighbourhood_binary_7', 'neighbourhood_binary_8', 'bathrooms', 'accommodates', 'bed_type', 'Airbed', 'Couch', 'Futon', 'Pull-out Sofa', 'Real Bed', 'room_type', 'Entire home/apt', 'Private room', 'Shared room', 'property_binary_encoded_0', 'property_binary_encoded_1', 'property_binary_encoded_2', 'property_binary_encoded_3', 'property_binary_encoded_4']\n"
     ]
    }
   ],
   "source": [
    "# TODO: add property_type to features --> encoding\n",
    "features = ['num_amenities', 'bedrooms', 'beds',\n",
    "            'neighbourhood_binary_0', 'neighbourhood_binary_1', \n",
    "            'neighbourhood_binary_2', 'neighbourhood_binary_3',\n",
    "            'neighbourhood_binary_4', 'neighbourhood_binary_5',\n",
    "            'neighbourhood_binary_6', 'neighbourhood_binary_7',\n",
    "            'neighbourhood_binary_8', 'bathrooms', 'accommodates',\n",
    "            'bed_type', 'Airbed', 'Couch', 'Futon', 'Pull-out Sofa',\n",
    "            'Real Bed', 'room_type', 'Entire home/apt', 'Private room',\n",
    "            'Shared room']\n",
    "\n",
    "allFeatures = features + binary_encoded_properties\n",
    "\n",
    "print allFeatures\n",
    "\n",
    "pickle.dump(allFeatures, open( '../app/utils/modelFeatures.pkl', 'wb' ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mHelper = ModelHelper(listingsClean, listingsClean.price, allFeatures)\n",
    "\n",
    "# mHelper.test_models(models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{nan: 0,\n",
       " 'Adams': 0,\n",
       " 'Adams-Normandie': 1,\n",
       " 'Agoura Hills': 2,\n",
       " 'Airbed': 0,\n",
       " 'Alhambra': 3,\n",
       " 'Alki': 4,\n",
       " 'Allston': 5,\n",
       " 'Alondra Park': 6,\n",
       " 'Altadena': 7,\n",
       " 'Angeles Crest': 8,\n",
       " 'Apartment': 1,\n",
       " 'Arbor Heights': 9,\n",
       " 'Arcadia': 10,\n",
       " 'Arleta': 11,\n",
       " 'Arlington Heights': 12,\n",
       " 'Artesia': 13,\n",
       " 'Athens': 14,\n",
       " 'Atlantic': 15,\n",
       " 'Atwater Village': 16,\n",
       " 'Avocado Heights': 17,\n",
       " 'Azusa': 18,\n",
       " 'Back Bay': 19,\n",
       " 'Baldwin Hills/Crenshaw': 20,\n",
       " 'Baldwin Park': 21,\n",
       " 'Bay Village': 22,\n",
       " 'Bayview': 23,\n",
       " 'Beacon Hill': 24,\n",
       " 'Bed & Breakfast': 2,\n",
       " 'Bel-Air': 25,\n",
       " 'Bell': 26,\n",
       " 'Bellflower': 27,\n",
       " 'Belltown': 28,\n",
       " 'Bernal Heights': 29,\n",
       " 'Beverly Crest': 30,\n",
       " 'Beverly Grove': 31,\n",
       " 'Beverly Hills': 32,\n",
       " 'Beverlywood': 33,\n",
       " 'Bitter Lake': 34,\n",
       " 'Boat': 3,\n",
       " 'Boyle Heights': 35,\n",
       " 'Bradbury': 36,\n",
       " 'Brentwood': 37,\n",
       " 'Briarcliff': 38,\n",
       " 'Brighton': 39,\n",
       " 'Brightwood Park, Crestwood, Petworth': 40,\n",
       " 'Broadview': 41,\n",
       " 'Broadway': 42,\n",
       " 'Broadway-Manchester': 43,\n",
       " 'Brookland, Brentwood, Langdon': 44,\n",
       " 'Bryant': 45,\n",
       " 'Bungalow': 4,\n",
       " 'Burbank': 46,\n",
       " 'Cabin': 5,\n",
       " 'Calabasas': 47,\n",
       " 'Camper/RV': 6,\n",
       " 'Canoga Park': 48,\n",
       " 'Capitol Hill, Lincoln Park': 49,\n",
       " 'Capitol View, Marshall Heights, Benning Heights': 50,\n",
       " 'Carson': 51,\n",
       " 'Carthay': 52,\n",
       " 'Castle': 7,\n",
       " 'Castro/Upper Market': 53,\n",
       " 'Cathedral Heights, McLean Gardens, Glover Park': 54,\n",
       " 'Cedar Park': 55,\n",
       " 'Central Business District': 56,\n",
       " 'Central-Alameda': 57,\n",
       " 'Century City': 58,\n",
       " 'Cerritos': 59,\n",
       " 'Chalet': 8,\n",
       " 'Charlestown': 60,\n",
       " 'Charter Oak': 61,\n",
       " 'Chatsworth': 62,\n",
       " 'Cheviot Hills': 63,\n",
       " 'Chinatown': 64,\n",
       " 'Citrus': 65,\n",
       " 'Claremont': 66,\n",
       " 'Cleveland Park, Woodley Park, Massachusetts Avenue Heights, Woodland-Normanstone Terrace': 67,\n",
       " 'Colonial Village, Shepherd Park, North Portal Estates': 68,\n",
       " 'Columbia City': 69,\n",
       " 'Columbia Heights, Mt. Pleasant, Pleasant Plains, Park View': 70,\n",
       " 'Commerce': 71,\n",
       " 'Compton': 72,\n",
       " 'Condominium': 9,\n",
       " 'Congress Heights, Bellevue, Washington Highlands': 73,\n",
       " 'Couch': 1,\n",
       " 'Covina': 74,\n",
       " 'Crocker Amazon': 75,\n",
       " 'Crown Hill': 76,\n",
       " 'Culver City': 77,\n",
       " 'Cypress Park': 78,\n",
       " 'Deanwood, Burrville, Grant Park, Lincoln Heights, Fairmont Heights': 79,\n",
       " 'Del Aire': 80,\n",
       " 'Del Rey': 81,\n",
       " 'Diamond Bar': 82,\n",
       " 'Diamond Heights': 83,\n",
       " 'Dorchester': 84,\n",
       " 'Dorm': 10,\n",
       " 'Douglas, Shipley Terrace': 85,\n",
       " 'Downey': 86,\n",
       " 'Downtown': 87,\n",
       " 'Downtown, Chinatown, Penn Quarters, Mount Vernon Square, North Capitol Street': 88,\n",
       " 'Downtown/Civic Center': 89,\n",
       " 'Duarte': 90,\n",
       " 'Dunlap': 91,\n",
       " 'Dupont Circle, Connecticut Avenue/K Street': 92,\n",
       " 'Eagle Rock': 93,\n",
       " 'Earth House': 11,\n",
       " 'East Boston': 94,\n",
       " 'East Compton': 95,\n",
       " 'East Hollywood': 96,\n",
       " 'East La Mirada': 97,\n",
       " 'East Los Angeles': 98,\n",
       " 'East Pasadena': 99,\n",
       " 'East Queen Anne': 100,\n",
       " 'East San Gabriel': 101,\n",
       " 'Eastlake': 102,\n",
       " 'Eastland Gardens, Kenilworth': 103,\n",
       " 'Echo Park': 104,\n",
       " 'Edgewood, Bloomingdale, Truxton Circle, Eckington': 105,\n",
       " 'El Monte': 106,\n",
       " 'El Segundo': 107,\n",
       " 'El Sereno': 108,\n",
       " 'Elysian Park': 109,\n",
       " 'Elysian Valley': 110,\n",
       " 'Encino': 111,\n",
       " 'Entire home/apt': 2,\n",
       " 'Excelsior': 112,\n",
       " 'Exposition Park': 113,\n",
       " 'Fairfax': 114,\n",
       " 'Fairfax Village, Naylor Gardens, Hillcrest, Summit Park': 115,\n",
       " 'Fairmount Park': 116,\n",
       " 'Fauntleroy': 117,\n",
       " 'Fenway': 118,\n",
       " 'Financial District': 119,\n",
       " 'First Hill': 120,\n",
       " 'Fremont': 121,\n",
       " 'Friendship Heights, American University Park, Tenleytown': 122,\n",
       " 'Futon': 2,\n",
       " 'Gardena': 123,\n",
       " 'Gatewood': 124,\n",
       " 'Genesee': 125,\n",
       " 'Georgetown': 126,\n",
       " 'Georgetown, Burleith/Hillandale': 127,\n",
       " 'Glassell Park': 128,\n",
       " 'Glen Park': 129,\n",
       " 'Glendale': 130,\n",
       " 'Glendora': 131,\n",
       " 'Golden Gate Park': 132,\n",
       " 'Gramercy Park': 133,\n",
       " 'Granada Hills': 134,\n",
       " 'Green Lake': 135,\n",
       " 'Green Meadows': 136,\n",
       " 'Greenwood': 137,\n",
       " 'Griffith Park': 138,\n",
       " 'Hacienda Heights': 139,\n",
       " 'Haight Ashbury': 140,\n",
       " 'Haller Lake': 141,\n",
       " 'Hancock Park': 142,\n",
       " 'Harbor City': 143,\n",
       " 'Harbor Gateway': 144,\n",
       " 'Harrison/Denny-Blaine': 145,\n",
       " 'Harvard Heights': 146,\n",
       " 'Hawaiian Gardens': 147,\n",
       " 'Hawthorne': 148,\n",
       " 'Hawthorne, Barnaby Woods, Chevy Chase': 149,\n",
       " 'Hermosa Beach': 150,\n",
       " 'High Point': 151,\n",
       " 'Highland Park': 152,\n",
       " 'Historic Anacostia': 153,\n",
       " 'Historic South-Central': 154,\n",
       " 'Holly Park': 155,\n",
       " 'Hollywood': 156,\n",
       " 'Hollywood Hills': 157,\n",
       " 'Hollywood Hills West': 158,\n",
       " 'House': 12,\n",
       " 'Howard University, Le Droit Park, Cardozo/Shaw': 159,\n",
       " 'Huntington Park': 160,\n",
       " 'Hut': 13,\n",
       " 'Hyde Park': 161,\n",
       " 'Industrial District': 162,\n",
       " 'Industry': 163,\n",
       " 'Inglewood': 164,\n",
       " 'Inner Richmond': 165,\n",
       " 'Inner Sunset': 166,\n",
       " 'Interbay': 167,\n",
       " 'International District': 168,\n",
       " 'Island': 14,\n",
       " 'Ivy City, Arboretum, Trinidad, Carver Langston': 169,\n",
       " 'Jamaica Plain': 170,\n",
       " 'Jefferson Park': 171,\n",
       " 'Kalorama Heights, Adams Morgan, Lanier Heights': 172,\n",
       " 'Koreatown': 173,\n",
       " 'La Ca\\xc3\\xb1ada Flintridge': 174,\n",
       " 'La Crescenta-Montrose': 175,\n",
       " 'La Habra Heights': 176,\n",
       " 'La Mirada': 177,\n",
       " 'La Puente': 178,\n",
       " 'La Verne': 179,\n",
       " 'Ladera Heights': 180,\n",
       " 'Lake Balboa': 181,\n",
       " 'Lakeshore': 182,\n",
       " 'Lakewood': 183,\n",
       " 'Lamont Riggs, Queens Chapel, Fort Totten, Pleasant Hill': 184,\n",
       " 'Larchmont': 185,\n",
       " 'Laurelhurst': 186,\n",
       " 'Lawndale': 187,\n",
       " 'Lawton Park': 188,\n",
       " 'Leather District': 189,\n",
       " 'Leimert Park': 190,\n",
       " 'Leschi': 191,\n",
       " 'Lighthouse': 15,\n",
       " 'Lincoln Heights': 192,\n",
       " 'Loft': 16,\n",
       " 'Lomita': 193,\n",
       " 'Long Beach': 194,\n",
       " 'Longwood Medical Area': 195,\n",
       " 'Lopez/Kagel Canyons': 196,\n",
       " 'Los Feliz': 197,\n",
       " 'Lower Queen Anne': 198,\n",
       " 'Loyal Heights': 199,\n",
       " 'Lynwood': 200,\n",
       " 'Madison Park': 201,\n",
       " 'Madrona': 202,\n",
       " 'Malibu': 203,\n",
       " 'Manchester Square': 204,\n",
       " 'Manhattan Beach': 205,\n",
       " 'Mann': 206,\n",
       " 'Maple Leaf': 207,\n",
       " 'Mar Vista': 208,\n",
       " 'Marina': 209,\n",
       " 'Marina del Rey': 210,\n",
       " 'Mattapan': 211,\n",
       " 'Matthews Beach': 212,\n",
       " 'Mayfair, Hillbrook, Mahaning Heights': 213,\n",
       " 'Mayflower Village': 214,\n",
       " 'Meadowbrook': 215,\n",
       " 'Mid-Beacon Hill': 216,\n",
       " 'Mid-City': 217,\n",
       " 'Mid-Wilshire': 218,\n",
       " 'Minor': 219,\n",
       " 'Mission': 220,\n",
       " 'Mission Hill': 221,\n",
       " 'Monrovia': 222,\n",
       " 'Montebello': 223,\n",
       " 'Montecito Heights': 224,\n",
       " 'Monterey Park': 225,\n",
       " 'Montlake': 226,\n",
       " 'Mount Baker': 227,\n",
       " 'Mount Washington': 228,\n",
       " 'Near Southeast, Navy Yard': 229,\n",
       " 'Nob Hill': 230,\n",
       " 'Noe Valley': 231,\n",
       " 'North Admiral': 232,\n",
       " 'North Beach': 233,\n",
       " 'North Beach/Blue Ridge': 234,\n",
       " 'North Beacon Hill': 235,\n",
       " 'North Cleveland Park, Forest Hills, Van Ness': 236,\n",
       " 'North College Park': 237,\n",
       " 'North Delridge': 238,\n",
       " 'North End': 239,\n",
       " 'North Hills': 240,\n",
       " 'North Hollywood': 241,\n",
       " 'North Michigan Park, Michigan Park, University Heights': 242,\n",
       " 'North Queen Anne': 243,\n",
       " 'North Whittier': 244,\n",
       " 'Northridge': 245,\n",
       " 'Norwalk': 246,\n",
       " 'Ocean View': 247,\n",
       " 'Olympic Hills': 248,\n",
       " 'Other': 17,\n",
       " 'Outer Mission': 249,\n",
       " 'Outer Richmond': 250,\n",
       " 'Outer Sunset': 251,\n",
       " 'Pacific Heights': 252,\n",
       " 'Pacific Palisades': 253,\n",
       " 'Pacoima': 254,\n",
       " 'Palms': 255,\n",
       " 'Palos Verdes Estates': 256,\n",
       " 'Panorama City': 257,\n",
       " 'Paramount': 258,\n",
       " 'Parking Space': 18,\n",
       " 'Parkside': 259,\n",
       " 'Pasadena': 260,\n",
       " 'Phinney Ridge': 261,\n",
       " 'Pico Rivera': 262,\n",
       " 'Pico-Robertson': 263,\n",
       " 'Pico-Union': 264,\n",
       " 'Pike-Market': 265,\n",
       " 'Pinehurst': 266,\n",
       " 'Pioneer Square': 267,\n",
       " 'Plane': 19,\n",
       " 'Playa Vista': 268,\n",
       " 'Playa del Rey': 269,\n",
       " 'Pomona': 270,\n",
       " 'Portage Bay': 271,\n",
       " 'Porter Ranch': 272,\n",
       " 'Potrero Hill': 273,\n",
       " 'Presidio': 274,\n",
       " 'Presidio Heights': 275,\n",
       " 'Private room': 1,\n",
       " 'Pull-out Sofa': 3,\n",
       " 'Rainier Beach': 276,\n",
       " 'Ramona': 277,\n",
       " 'Rancho Palos Verdes': 278,\n",
       " 'Rancho Park': 279,\n",
       " 'Ravenna': 280,\n",
       " 'Real Bed': 4,\n",
       " 'Redondo Beach': 281,\n",
       " 'Reseda': 282,\n",
       " 'River Terrace, Benning, Greenway, Dupont Park': 283,\n",
       " 'Riverview': 284,\n",
       " 'Rolling Hills Estates': 285,\n",
       " 'Roosevelt': 286,\n",
       " 'Rosemead': 287,\n",
       " 'Roslindale': 288,\n",
       " 'Rowland Heights': 289,\n",
       " 'Roxbury': 290,\n",
       " 'Roxhill': 291,\n",
       " 'Russian Hill': 292,\n",
       " 'San Dimas': 293,\n",
       " 'San Gabriel': 294,\n",
       " 'San Marino': 295,\n",
       " 'San Pasqual': 296,\n",
       " 'San Pedro': 297,\n",
       " 'Santa Clarita': 298,\n",
       " 'Santa Fe Springs': 299,\n",
       " 'Santa Monica': 300,\n",
       " 'Sawtelle': 301,\n",
       " 'Seacliff': 302,\n",
       " 'Seaview': 303,\n",
       " 'Sepulveda Basin': 304,\n",
       " 'Seward Park': 305,\n",
       " 'Shadow Hills': 306,\n",
       " 'Shared room': 0,\n",
       " 'Shaw, Logan Circle': 307,\n",
       " 'Sheridan, Barry Farm, Buena Vista': 308,\n",
       " 'Sherman Oaks': 309,\n",
       " 'Sierra Madre': 310,\n",
       " 'Signal Hill': 311,\n",
       " 'Silver Lake': 312,\n",
       " 'South Beacon Hill': 313,\n",
       " 'South Boston': 314,\n",
       " 'South Boston Waterfront': 315,\n",
       " 'South Delridge': 316,\n",
       " 'South Diamond Bar': 317,\n",
       " 'South El Monte': 318,\n",
       " 'South End': 319,\n",
       " 'South Lake Union': 320,\n",
       " 'South Park': 321,\n",
       " 'South Pasadena': 322,\n",
       " 'South San Gabriel': 323,\n",
       " 'South Whittier': 324,\n",
       " 'South of Market': 325,\n",
       " 'Southeast Antelope Valley': 326,\n",
       " 'Southeast Magnolia': 327,\n",
       " 'Southwest Employment Area, Southwest/Waterfront, Fort McNair, Buzzard Point': 328,\n",
       " 'Spring Valley, Palisades, Wesley Heights, Foxhall Crescent, Foxhall Village, Georgetown Reservoir': 329,\n",
       " 'Stevens': 330,\n",
       " 'Studio City': 331,\n",
       " 'Sun Valley': 332,\n",
       " 'Sunland': 333,\n",
       " 'Sunset Hill': 334,\n",
       " 'Sylmar': 335,\n",
       " 'Takoma, Brightwood, Manor Park': 336,\n",
       " 'Tarzana': 337,\n",
       " 'Temple City': 338,\n",
       " 'Tent': 20,\n",
       " 'Tipi': 21,\n",
       " 'Toluca Lake': 339,\n",
       " 'Topanga': 340,\n",
       " 'Torrance': 341,\n",
       " 'Townhouse': 22,\n",
       " 'Train': 23,\n",
       " 'Treasure Island/YBI': 342,\n",
       " 'Treehouse': 24,\n",
       " 'Tujunga': 343,\n",
       " 'Tujunga Canyons': 344,\n",
       " 'Twin Peaks': 345,\n",
       " 'Twining, Fairlawn, Randle Highlands, Penn Branch, Fort Davis Park, Fort Dupont': 346,\n",
       " 'Unincorporated Santa Monica Mountains': 347,\n",
       " 'Union Station, Stanton Park, Kingman Park': 348,\n",
       " 'Universal City': 349,\n",
       " 'University District': 350,\n",
       " 'University Park': 351,\n",
       " 'Valinda': 352,\n",
       " 'Valley Glen': 353,\n",
       " 'Valley Village': 354,\n",
       " 'Van Nuys': 355,\n",
       " 'Venice': 356,\n",
       " 'Vermont Knolls': 357,\n",
       " 'Vermont Square': 358,\n",
       " 'Vermont Vista': 359,\n",
       " 'Vernon': 360,\n",
       " 'Veterans Administration': 361,\n",
       " 'Victory Heights': 362,\n",
       " 'View Park-Windsor Hills': 363,\n",
       " 'View Ridge': 364,\n",
       " 'Villa': 25,\n",
       " 'Vincent': 365,\n",
       " 'Visitacion Valley': 366,\n",
       " 'Wallingford': 367,\n",
       " 'Walnut': 368,\n",
       " 'Watts': 369,\n",
       " 'Wedgwood': 370,\n",
       " 'West Adams': 371,\n",
       " 'West Carson': 372,\n",
       " 'West Covina': 373,\n",
       " 'West End': 374,\n",
       " 'West End, Foggy Bottom, GWU': 375,\n",
       " 'West Hills': 376,\n",
       " 'West Hollywood': 377,\n",
       " 'West Los Angeles': 378,\n",
       " 'West Queen Anne': 379,\n",
       " 'West Roxbury': 380,\n",
       " 'West Woodland': 381,\n",
       " 'West of Twin Peaks': 382,\n",
       " 'Westchester': 383,\n",
       " 'Western Addition': 384,\n",
       " 'Westlake': 385,\n",
       " 'Westlake Village': 386,\n",
       " 'Westmont': 387,\n",
       " 'Westwood': 388,\n",
       " 'Whittier': 389,\n",
       " 'Whittier Heights': 390,\n",
       " 'Willowbrook': 391,\n",
       " 'Windermere': 392,\n",
       " 'Windsor Square': 393,\n",
       " 'Winnetka': 394,\n",
       " 'Woodland Hills': 395,\n",
       " 'Woodland/Fort Stanton, Garfield Heights, Knox Hill': 396,\n",
       " 'Woodridge, Fort Lincoln, Gateway': 397,\n",
       " 'Yesler Terrace': 398,\n",
       " 'Yurt': 26}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save dict mappings\n",
    "mHelper.save_mappings()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
